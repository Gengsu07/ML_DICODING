{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basepath = os.path.join(os.getcwd(),'images')\n",
    "# trainpath = os.path.join(basepath,'train')\n",
    "# valpath = os.path.join(basepath,'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainpath = '/Users/sugengw07/Documents/DEVELOPMENT/images/train'\n",
    "valpath = '/Users/sugengw07/Documents/DEVELOPMENT/images/val'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Langkah selanjutnya, kita akan menerapkan ImageDataGenerator untuk data latih dan data validasi. ImageDataGenerator merupakan sebuah fungsi yang sangat berguna untuk mempersiapkan data latih dan data validasi. Beberapa kemudahan yang disediakan ImageDataGenerator antara lain, preprocessing data, pelabelan sampel otomatis, dan augmentasi gambar.\n",
    "\n",
    "Augmentasi gambar merupakan sebuah teknik yang dapat digunakan untuk memperbanyak data latih dengan cara menduplikasi gambar yang telah ada dengan menambahkan variasi tertentu. Anda akan mempelajari lebih dalam terkait teknik ini pada kelas “Belajar Pengembangan Machine Learning”. Anda juga dapat melihat detail mengenai augmentasi gambar menggunakan ImageDataGenerator pada tautan berikut. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    horizontal_flip = True,\n",
    "    shear_range = 0.2,\n",
    "    fill_mode = 'nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selanjutnya, siapkan data latih dan validasi dari kumpulan data gambar yang di-load dalam memori melalui fungsi flow() berikut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 192 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    trainpath, # direktori data latih\n",
    "    target_size = (150,150), # mengubah resolusi seluruh gambar menjadi 150x150 piksel\n",
    "    batch_size = 4,\n",
    "    class_mode = 'binary' # karena ini merupakan masalah klasifikasi 2 kelas, gunakan class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    valpath,\n",
    "    target_size = (150, 150),\n",
    "    batch_size = 4,\n",
    "    class_mode = 'binary'\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah data siap, kita bisa membangun model Convolutional Neural Network (CNN). Pembuatan model CNN pada keras mirip dengan pembuatan model Multi Layer Perceptron (MLP) yang dibahas pada modul sebelumnya. Perbedaannya terdapat pada empat lapis layer konvolusi dan max pooling. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda tentu masih ingat bahwa fungsi dari layer konvolusi adalah untuk mengekstraksi atribut pada gambar. Sedangkan layer max pooling berguna untuk mereduksi resolusi gambar sehingga proses pelatihan model lebih cepat. Nah, pada model CNN, proses klasifikasi gambar hanya berfokus pada atribut-atribut unik yang membedakan tiap kategori. Sehingga, teknik ini dinilai lebih optimal dibandingkan hanya menggunakan model MLP yang membedakan tiap kategori dengan melihat keseluruhan piksel-piksel pada gambar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape = (150, 150, 3)),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Conv2D(512, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPool2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "melihat summary dari arsitektur model yang telah kita buat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 74, 74, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 17, 17, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 15, 15, 512)       590336    \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12845568  \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 513       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 13,529,665\n",
      "Trainable params: 13,529,665\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model yang kita buat terdiri dari empat lapis Convolutional dan MaxPoling layer, sebuah flatten layer, serta dua buah dense layer. Ingatlah bahwa dense layer terakhir merupakan output layer. Pada kasus klasifikasi biner, output model merupakan angka tunggal antara 0 dan 1. Sehingga, kita set dense layer terakhir = 1. Sementara itu, kolom “Param #” berisi informasi mengenai jumlah parameter pada tiap layer.\n",
    "\n",
    "Selanjutnya, kolom “Output Shape” berisi informasi ukuran output yang dihasilkan tiap layer. Jika diperhatikan, ukuran input gambar yang telah didefinisikan sebelumnya adalah sebesar (150, 150). Tapi pada convolutional layer pertama, setiap satu input gambar akan menghasilkan ukuran output (148, 148) sebanyak 32 gambar. Ukuran tersebut berkurang karena kita menggunakan filter dengan ukuran (3, 3) dengan jumlah filter sebanyak 32 filter. Sehingga, tiap satu input gambar akan menghasilkan 32 gambar baru dengan ukuran (148, 148). \n",
    "\n",
    "Kemudian, resolusi tiap gambar akan diperkecil dengan tetap mempertahankan informasi pada gambar menggunakan MaxPoling layer yang berukuran (2, 2). Hal ini  akan menghasilkan ukuran output gambar sebesar (74, 74). Nah, proses tersebut juga berlaku untuk Convolutional dan MaxPoling layer yang lain. \n",
    "\n",
    "Berikutnya, mari perhatikan flatten layer. Output dari MaxPoling layer terakhir yang terdiri dari 512 gambar dengan ukuran (7, 7) akan diubah ke dalam bentuk array 1D (tensor 1D). Hal ini  akan menghasilkan output berukuran (25088). \n",
    "\n",
    "Nah, output tersebut kemudian masuk ke dalam dense layer pertama yang memiliki 512 neuron. Sehingga, ia akan menghasilkan output dengan ukuran (512). Selanjutnya, output ini akan masuk pada dense layer kedua yang memiliki 1 neuron sehingga akan menghasilkan output dengan ukuran (1). Output dari layer terakhir inilah yang digunakan sebagai hasil akhir model untuk kasus klasifikasi biner."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tahap selanjutnya adalah melakukan compile model tersebut menggunakan fungsi compile(). Pada tahap ini, kita juga menentukan loss function serta optimizer yang akan digunakan. Loss function yang digunakan pada kasus klasifikasi biner adalah \"binary_crossentropy\". Selain itu, optimizer yang digunakan  pada kasus ini adalah \"Adam optimizer\". Adam optimizer dipilih karena mudah diterapkan, lebih efisien secara komputasi dan kebutuhan memori yang lebih kecil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'binary_crossentropy',\n",
    "              optimizer = tf.optimizers.Adam(),\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### latih model dengan model.fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 13:44:03.158110: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-04-01 13:44:25.364391: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 - 24s - loss: 0.7060 - accuracy: 0.5500 - val_loss: 0.6911 - val_accuracy: 0.7000 - 24s/epoch - 978ms/step\n",
      "Epoch 2/20\n",
      "25/25 - 16s - loss: 0.6780 - accuracy: 0.5400 - val_loss: 0.6920 - val_accuracy: 0.5000 - 16s/epoch - 648ms/step\n",
      "Epoch 3/20\n",
      "25/25 - 18s - loss: 0.6920 - accuracy: 0.5300 - val_loss: 0.6774 - val_accuracy: 0.5000 - 18s/epoch - 708ms/step\n",
      "Epoch 4/20\n",
      "25/25 - 14s - loss: 0.6983 - accuracy: 0.4500 - val_loss: 0.6851 - val_accuracy: 0.5000 - 14s/epoch - 566ms/step\n",
      "Epoch 5/20\n",
      "25/25 - 13s - loss: 0.7015 - accuracy: 0.5100 - val_loss: 0.6869 - val_accuracy: 0.5000 - 13s/epoch - 527ms/step\n",
      "Epoch 6/20\n",
      "25/25 - 13s - loss: 0.6932 - accuracy: 0.5100 - val_loss: 0.6245 - val_accuracy: 0.5500 - 13s/epoch - 515ms/step\n",
      "Epoch 7/20\n",
      "25/25 - 13s - loss: 0.6438 - accuracy: 0.6100 - val_loss: 0.6112 - val_accuracy: 0.6500 - 13s/epoch - 537ms/step\n",
      "Epoch 8/20\n",
      "25/25 - 13s - loss: 0.6126 - accuracy: 0.6600 - val_loss: 0.7331 - val_accuracy: 0.5000 - 13s/epoch - 514ms/step\n",
      "Epoch 9/20\n",
      "25/25 - 13s - loss: 0.6699 - accuracy: 0.5900 - val_loss: 0.6429 - val_accuracy: 0.6000 - 13s/epoch - 520ms/step\n",
      "Epoch 10/20\n",
      "25/25 - 13s - loss: 0.6547 - accuracy: 0.6900 - val_loss: 0.7329 - val_accuracy: 0.5000 - 13s/epoch - 514ms/step\n",
      "Epoch 11/20\n",
      "25/25 - 13s - loss: 0.7036 - accuracy: 0.4900 - val_loss: 0.6880 - val_accuracy: 0.5000 - 13s/epoch - 500ms/step\n",
      "Epoch 12/20\n",
      "25/25 - 13s - loss: 0.6896 - accuracy: 0.5900 - val_loss: 0.6825 - val_accuracy: 0.7000 - 13s/epoch - 508ms/step\n",
      "Epoch 13/20\n",
      "25/25 - 12s - loss: 0.6759 - accuracy: 0.6700 - val_loss: 0.6614 - val_accuracy: 0.6500 - 12s/epoch - 497ms/step\n",
      "Epoch 14/20\n",
      "25/25 - 13s - loss: 0.6490 - accuracy: 0.6200 - val_loss: 0.6171 - val_accuracy: 0.7000 - 13s/epoch - 513ms/step\n",
      "Epoch 15/20\n",
      "25/25 - 13s - loss: 0.6686 - accuracy: 0.6000 - val_loss: 0.5884 - val_accuracy: 0.7000 - 13s/epoch - 505ms/step\n",
      "Epoch 16/20\n",
      "25/25 - 14s - loss: 0.6243 - accuracy: 0.6400 - val_loss: 0.6066 - val_accuracy: 0.7500 - 14s/epoch - 555ms/step\n",
      "Epoch 17/20\n",
      "25/25 - 14s - loss: 0.5732 - accuracy: 0.7200 - val_loss: 0.5876 - val_accuracy: 0.6500 - 14s/epoch - 548ms/step\n",
      "Epoch 18/20\n",
      "25/25 - 15s - loss: 0.5006 - accuracy: 0.7300 - val_loss: 0.5566 - val_accuracy: 0.6500 - 15s/epoch - 595ms/step\n",
      "Epoch 19/20\n",
      "25/25 - 20s - loss: 0.5221 - accuracy: 0.7700 - val_loss: 0.5634 - val_accuracy: 0.6500 - 20s/epoch - 799ms/step\n",
      "Epoch 20/20\n",
      "25/25 - 14s - loss: 0.5461 - accuracy: 0.7200 - val_loss: 0.5462 - val_accuracy: 0.7000 - 14s/epoch - 545ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc5962e8790>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=25,\n",
    "    epochs=20,\n",
    "    validation_data= validation_generator,\n",
    "    validation_steps = 5,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "model_save = open('messy_clean_rooms.sav','wb') \n",
    "pickle.dump(model, model_save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
